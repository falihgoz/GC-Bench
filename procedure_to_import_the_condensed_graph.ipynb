{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the condensed graphs\n",
    "\n",
    "- the condensed graphs are appeared in the `./save` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 30])\n",
      "torch.Size([87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\falih\\AppData\\Local\\Temp\\ipykernel_36820\\2561472706.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x=torch.tensor(nodes, dtype=torch.float).to(device),\n",
      "C:\\Users\\falih\\AppData\\Local\\Temp\\ipykernel_36820\\2561472706.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(labels, dtype=torch.long).to(device),\n",
      "C:\\Users\\falih\\AppData\\Local\\Temp\\ipykernel_36820\\2561472706.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(edges, dtype=torch.long).to(device),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# example for traditional methods like: random, herding, and k-center:\n",
    "\n",
    "################ START OF DUMMY DATA #####################\n",
    "num_nodes = 87\n",
    "feature_dim = 30\n",
    "device=\"cuda:0\"\n",
    "# Random node features (size: [num_nodes, feature_dim])\n",
    "nodes = torch.randn(num_nodes, feature_dim, dtype=torch.float)\n",
    "# Random labels for nodes (size: [num_nodes])\n",
    "labels = torch.randint(0, 5, (num_nodes,), dtype=torch.long)  # Assuming 5 classes\n",
    "# Random edge index (size: [2, num_edges])\n",
    "num_edges = 200\n",
    "edges = torch.randint(0, num_nodes, (2, num_edges), dtype=torch.long)\n",
    "\n",
    "condensed_graph_path = \"save/random/idx_cornell_0.5_15.npy\"\n",
    "################ END OF DUMMY DATA #####################\n",
    "\n",
    "# supposed this the full graph produced by the flash\n",
    "graph = Data(\n",
    "    x=torch.tensor(nodes, dtype=torch.float).to(device),\n",
    "    y=torch.tensor(labels, dtype=torch.long).to(device),\n",
    "    edge_index=torch.tensor(edges, dtype=torch.long).to(device),\n",
    ")\n",
    "graph.n_id = torch.arange(graph.num_nodes)\n",
    "mask = torch.tensor([True] * graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "\n",
    "# this is the condensed graph based on the choosen indices in the npy file.\n",
    "selected_indices = np.load(condensed_graph_path)\n",
    "selected_indices_tensor = torch.tensor(selected_indices, dtype=torch.long).to(device)\n",
    "\n",
    "subset_mask = torch.zeros(graph.num_nodes, dtype=torch.bool).to(device)\n",
    "subset_mask[selected_indices_tensor] = True\n",
    "\n",
    "graph_subset = Data(\n",
    "    x=graph.x[subset_mask],\n",
    "    y=graph.y[subset_mask],\n",
    "    edge_index=graph.edge_index[\n",
    "        :, subset_mask[graph.edge_index[0]] & subset_mask[graph.edge_index[1]]\n",
    "    ],\n",
    ")\n",
    "\n",
    "graph_subset.n_id = torch.arange(graph.num_nodes)\n",
    "mask_subset = torch.tensor([True]*graph_subset.num_nodes, dtype=torch.bool)\n",
    "\n",
    "# Similar to in [20] https://github.com/Aisuko/flash_ids/blob/experiments/Theia.ipynb\n",
    "\n",
    "# for m_n in range(20):\n",
    "#     loader = NeighborLoader(\n",
    "#         graph_subset, num_neighbors=[-1, -1], batch_size=5000, input_nodes=mask_subset #try to lower the batch_size\n",
    "#     )\n",
    "#     total_loss = 0\n",
    "#     for subg in loader:\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(subg.x, subg.edge_index)\n",
    "#         loss = criterion(out, subg.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item() * subg.batch_size\n",
    "#     print(total_loss / mask.sum().item())\n",
    "\n",
    "#     loader = NeighborLoader(\n",
    "#         graph_subset, num_neighbors=[-1, -1], batch_size=5000, input_nodes=mask_subset #try to lower the batch_size\n",
    "#     )\n",
    "#     for subg in loader:\n",
    "#         model.eval()\n",
    "#         out = model(subg.x, subg.edge_index)\n",
    "\n",
    "#         sorted, indices = out.sort(dim=1, descending=True)\n",
    "#         conf = (sorted[:, 0] - sorted[:, 1]) / sorted[:, 0]\n",
    "#         conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "#         pred = indices[:, 0]\n",
    "#         cond = (pred == subg.y) | (conf >= 0.9)\n",
    "#         mask[subg.n_id[cond]] = False\n",
    "\n",
    "#     torch.save(model.state_dict(), f\"lword2vec_gnn_theia{m_n}_E3.pth\")\n",
    "#     print(f\"Model# {m_n}. {mask.sum().item()} nodes still misclassified \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below is an example of other graph distillation techniques (eg., SGDD, GCOND, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([149, 149])\n",
      "torch.Size([149, 30])\n",
      "torch.Size([149])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\falih\\AppData\\Local\\Temp\\ipykernel_22020\\978803369.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x=torch.tensor(nodes, dtype=torch.float).to(device),\n",
      "C:\\Users\\falih\\AppData\\Local\\Temp\\ipykernel_22020\\978803369.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(labels, dtype=torch.long).to(device),\n",
      "C:\\Users\\falih\\AppData\\Local\\Temp\\ipykernel_22020\\978803369.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(edges, dtype=torch.long).to(device),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "# example for modern graph distillation techniques (eg., SGDD, GCOND, etc.)\n",
    "\n",
    "################ START OF DUMMY DATA #####################\n",
    "\n",
    "adj_path = \"save/SGDD/adj_apt_dummy_0.5_15.pt\"\n",
    "adj = torch.load(adj_path)\n",
    "\n",
    "feature_path = \"save/SGDD/feat_apt_dummy_0.5_15.pt\"\n",
    "feats = torch.load(feature_path)\n",
    "\n",
    "label_path = \"save/SGDD/label_apt_dummy_0.5_15.pt\"\n",
    "labels = torch.load(label_path)\n",
    "\n",
    "print(adj.shape)\n",
    "print(feats.shape)\n",
    "print(labels.shape)\n",
    "device = \"cuda:0\"\n",
    "\n",
    "nodes = feats\n",
    "labels = labels\n",
    "edges, _ = dense_to_sparse(adj)\n",
    "\n",
    "################ END OF DUMMY DATA #####################\n",
    "\n",
    "# Similar to in [20] https://github.com/Aisuko/flash_ids/blob/experiments/Theia.ipynb\n",
    "\n",
    "graph = Data(\n",
    "    x=torch.tensor(nodes, dtype=torch.float).to(device),\n",
    "    y=torch.tensor(labels, dtype=torch.long).to(device),\n",
    "    edge_index=torch.tensor(edges, dtype=torch.long).to(device),\n",
    ")\n",
    "graph.n_id = torch.arange(graph.num_nodes)\n",
    "mask = torch.tensor([True] * graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "\n",
    "# for m_n in range(20):\n",
    "\n",
    "#     loader = NeighborLoader(\n",
    "#         graph, num_neighbors=[-1, -1], batch_size=5000, input_nodes=mask\n",
    "#     )\n",
    "#     total_loss = 0\n",
    "#     for subg in loader:\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(subg.x, subg.edge_index)\n",
    "#         loss = criterion(out, subg.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item() * subg.batch_size\n",
    "#     print(total_loss / mask.sum().item())\n",
    "\n",
    "#     loader = NeighborLoader(\n",
    "#         graph, num_neighbors=[-1, -1], batch_size=5000, input_nodes=mask\n",
    "#     )\n",
    "#     for subg in loader:\n",
    "#         model.eval()\n",
    "#         out = model(subg.x, subg.edge_index)\n",
    "\n",
    "#         sorted, indices = out.sort(dim=1, descending=True)\n",
    "#         conf = (sorted[:, 0] - sorted[:, 1]) / sorted[:, 0]\n",
    "#         conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "#         pred = indices[:, 0]\n",
    "#         cond = (pred == subg.y) | (conf >= 0.9)\n",
    "#         mask[subg.n_id[cond]] = False\n",
    "\n",
    "#     torch.save(model.state_dict(), f\"lword2vec_gnn_theia{m_n}_E3.pth\")\n",
    "#     print(f\"Model# {m_n}. {mask.sum().item()} nodes still misclassified \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
